{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "17YgzS_F7oeBo1wsVMuwkdNxV87emUVp4",
      "authorship_tag": "ABX9TyN1H3U9M3Fg0v/9GuHYmqSR",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fred-dev/wav_gan/blob/main/Fred_WAV_GAN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "  audio_folder = \"/content/drive/MyDrive/colab_storage/ronxgin_data_samples\"\n",
        "  json_folder = \"/content/drive/MyDrive/colab_storage/ronxgin_data_samples\"\n",
        "  model_path = \"/content/drive/MyDrive/colab_storage/colab_output\"\n",
        "  output_path = \"/content/drive/MyDrive/colab_storage/colab_output/\"\n",
        "\n"
      ],
      "metadata": {
        "id": "j-bx2eTsawdQ"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install wandb\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sNqJUbmNZn5v",
        "outputId": "97f68252-9117-49af-b6f7-a4ff4a8ba33c"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting wandb\n",
            "  Downloading wandb-0.14.0-py3-none-any.whl (2.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m25.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.9/dist-packages (from wandb) (5.9.4)\n",
            "Collecting GitPython!=3.1.29,>=1.0.0\n",
            "  Downloading GitPython-3.1.31-py3-none-any.whl (184 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m184.3/184.3 KB\u001b[0m \u001b[31m15.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: protobuf!=4.21.0,<5,>=3.15.0 in /usr/local/lib/python3.9/dist-packages (from wandb) (3.20.3)\n",
            "Collecting pathtools\n",
            "  Downloading pathtools-0.1.2.tar.gz (11 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: appdirs>=1.4.3 in /usr/local/lib/python3.9/dist-packages (from wandb) (1.4.4)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.9/dist-packages (from wandb) (6.0)\n",
            "Collecting setproctitle\n",
            "  Downloading setproctitle-1.3.2-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30 kB)\n",
            "Requirement already satisfied: Click!=8.0.0,>=7.0 in /usr/local/lib/python3.9/dist-packages (from wandb) (8.1.3)\n",
            "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from wandb) (2.27.1)\n",
            "Collecting sentry-sdk>=1.0.0\n",
            "  Downloading sentry_sdk-1.18.0-py2.py3-none-any.whl (194 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.8/194.8 KB\u001b[0m \u001b[31m16.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.9/dist-packages (from wandb) (67.6.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.9/dist-packages (from wandb) (4.5.0)\n",
            "Collecting docker-pycreds>=0.4.0\n",
            "  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
            "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.9/dist-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\n",
            "Collecting gitdb<5,>=4.0.1\n",
            "  Downloading gitdb-4.0.10-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 KB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests<3,>=2.0.0->wandb) (2022.12.7)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests<3,>=2.0.0->wandb) (3.4)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests<3,>=2.0.0->wandb) (1.26.15)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests<3,>=2.0.0->wandb) (2.0.12)\n",
            "Collecting smmap<6,>=3.0.1\n",
            "  Downloading smmap-5.0.0-py3-none-any.whl (24 kB)\n",
            "Building wheels for collected packages: pathtools\n",
            "  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pathtools: filename=pathtools-0.1.2-py3-none-any.whl size=8807 sha256=c0de848947dd3709c99871c7831f0b2d494a8afad21477bafdf828eadfbec0ae\n",
            "  Stored in directory: /root/.cache/pip/wheels/b7/0a/67/ada2a22079218c75a88361c0782855cc72aebc4d18d0289d05\n",
            "Successfully built pathtools\n",
            "Installing collected packages: pathtools, smmap, setproctitle, sentry-sdk, docker-pycreds, gitdb, GitPython, wandb\n",
            "Successfully installed GitPython-3.1.31 docker-pycreds-0.4.0 gitdb-4.0.10 pathtools-0.1.2 sentry-sdk-1.18.0 setproctitle-1.3.2 smmap-5.0.0 wandb-0.14.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "I2fHyssYY8N6"
      },
      "outputs": [],
      "source": [
        "# 1. Import required libraries\n",
        "import os\n",
        "import json\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torchaudio.transforms as T\n",
        "import torchaudio\n",
        "import numpy as np\n",
        "import wandb\n",
        "from datetime import datetime\n",
        "import torch.nn.functional as F\n",
        "from torch.nn.utils.rnn import pack_sequence\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "wandb.login()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "XJ_I83A2Z7VZ",
        "outputId": "a50da139-50e4-42a0-fc48-3540f55f769b"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
              "            function loadScript(url) {\n",
              "            return new Promise(function(resolve, reject) {\n",
              "                let newScript = document.createElement(\"script\");\n",
              "                newScript.onerror = reject;\n",
              "                newScript.onload = resolve;\n",
              "                document.body.appendChild(newScript);\n",
              "                newScript.src = url;\n",
              "            });\n",
              "            }\n",
              "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
              "            const iframe = document.createElement('iframe')\n",
              "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
              "            document.body.appendChild(iframe)\n",
              "            const handshake = new Postmate({\n",
              "                container: iframe,\n",
              "                url: 'https://wandb.ai/authorize'\n",
              "            });\n",
              "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
              "            handshake.then(function(child) {\n",
              "                child.on('authorize', data => {\n",
              "                    clearTimeout(timeout)\n",
              "                    resolve(data)\n",
              "                });\n",
              "            });\n",
              "            })\n",
              "        });\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. Define the dataset class\n",
        "from torch.nn.utils.rnn import pack_sequence\n",
        "\n",
        "class AudioDataset(Dataset):\n",
        "    def __init__(self, audio_folder, json_folder, transform=None):\n",
        "        self.audio_folder = audio_folder\n",
        "        self.json_folder = json_folder\n",
        "        self.transform = transform\n",
        "        self.file_list = [f for f in os.listdir(audio_folder) if f.endswith(\".wav\")]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.file_list)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        audio_path = os.path.join(self.audio_folder, self.file_list[idx])\n",
        "        json_path = os.path.join(self.json_folder, os.path.splitext(self.file_list[idx])[0].rstrip('_P') + \".json\")\n",
        "\n",
        "        print(f\"Loading {idx+1}/{len(self.file_list)}: {audio_path}\")\n",
        "\n",
        "        waveform, _ = torchaudio.load(audio_path)\n",
        "\n",
        "        with open(json_path) as f:\n",
        "            data = json.load(f)\n",
        "\n",
        "        params = [\n",
        "            data[\"coord\"][\"lat\"],\n",
        "            data[\"coord\"][\"lon\"],\n",
        "            data[\"wind\"][\"deg\"],\n",
        "            data[\"main\"][\"humidity\"],\n",
        "            data[\"wind\"][\"speed\"],\n",
        "            data[\"wind\"][\"deg\"],\n",
        "            data[\"main\"][\"pressure\"],\n",
        "            data[\"elevation\"],\n",
        "            data[\"minutesOfDay\"],\n",
        "            data[\"dayOfYear\"],\n",
        "        ]\n",
        "\n",
        "        if self.transform:\n",
        "            waveform = self.transform(waveform)\n",
        "\n",
        "        return waveform.squeeze(), torch.tensor(params, dtype=torch.float32)\n",
        "\n",
        "\n",
        "def collate_fn(batch):\n",
        "    # Sort the batch by sequence length (descending order)\n",
        "    batch = sorted(batch, key=lambda x: x[0].size(1), reverse=True)\n",
        "    \n",
        "    # Create a list of the sequence lengths for packed sequences\n",
        "    seq_lengths = [x[0].size(1) for x in batch]\n",
        "    \n",
        "    # Pad the batch to have sequences of equal length\n",
        "    padded_batch = [(\n",
        "        F.pad(item[0], pad=(0, 0, 0, max(seq_lengths) - item[0].size(-1))),  # Padded sequence\n",
        "        item[1],  # Original sequence length\n",
        "        item[2]  # Parameters\n",
        "    ) for item in batch]\n",
        "    \n",
        "    # Convert the padded batch to a packed sequence\n",
        "    packed_batch = nn.utils.rnn.pack_sequence([x[0] for x in padded_batch])\n",
        "    \n",
        "    return packed_batch, torch.tensor([x[1] for x in padded_batch], dtype=torch.long), [x[2] for x in padded_batch]\n",
        "\n"
      ],
      "metadata": {
        "id": "5x4OK5fEZCfA"
      },
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Generator(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, num_layers, audio_dim):\n",
        "        super(Generator, self).__init__()\n",
        "\n",
        "        self.input_dim = input_dim\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.num_layers = num_layers\n",
        "        self.audio_dim = audio_dim\n",
        "\n",
        "        self.lstm = nn.LSTM(input_dim, hidden_dim, num_layers, batch_first=True)\n",
        "        self.linear = nn.Linear(hidden_dim, audio_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        output, _ = self.lstm(x)\n",
        "        output = self.linear(output)\n",
        "        return output\n",
        "\n",
        "\n",
        "class Discriminator(nn.Module):\n",
        "    def __init__(self, audio_dim, hidden_dim, num_layers, output_dim):\n",
        "        super(Discriminator, self).__init__()\n",
        "\n",
        "        self.audio_dim = audio_dim\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.num_layers = num_layers\n",
        "        self.output_dim = output_dim\n",
        "\n",
        "        self.lstm = nn.LSTM(audio_dim, hidden_dim, num_layers, batch_first=True)\n",
        "        self.linear = nn.Linear(hidden_dim, output_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        output, _ = self.lstm(x)\n",
        "        output = self.linear(output[:, -1, :])\n",
        "        return output\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "20abhatfZGXf"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_discriminator(real_data, fake_data, params, optimizer, criterion):\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    real_preds = discriminator(torch.cat((real_data, params), dim=1))\n",
        "    real_loss = criterion(real_preds, torch.ones_like(real_preds))\n",
        "\n",
        "    fake_preds = discriminator(torch.cat((fake_data, params), dim=1))\n",
        "    fake_loss = criterion(fake_preds, torch.zeros_like(fake_preds))\n",
        "\n",
        "    total_loss = real_loss + fake_loss\n",
        "    total_loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    return total_loss.item()\n",
        "\n",
        "def train_generator(fake_data, params, optimizer, criterion):\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    preds = discriminator(torch.cat((fake_data, params), dim=1))\n",
        "    loss = criterion(preds, torch.ones_like(preds))\n",
        "\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    return loss.item()\n"
      ],
      "metadata": {
        "id": "TkHn3Vq6ZJ_Y"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 5. Connect to Weights and Biases for tracking progress\n",
        "wandb.init(project=\"audio-gan\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 230
        },
        "id": "shzA76G_ZNr4",
        "outputId": "412173a5-3aa9-4da3-9942-07bdec2cceeb"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Finishing last run (ID:2hb9ix2q) before initializing another..."
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">cosmic-pond-14</strong> at: <a href='https://wandb.ai/syntheticornithology/audio-gan/runs/2hb9ix2q' target=\"_blank\">https://wandb.ai/syntheticornithology/audio-gan/runs/2hb9ix2q</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20230402_032017-2hb9ix2q/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Successfully finished last run (ID:2hb9ix2q). Initializing new run:<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.14.0"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20230402_032828-98x1il3w</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/syntheticornithology/audio-gan/runs/98x1il3w' target=\"_blank\">atomic-frog-15</a></strong> to <a href='https://wandb.ai/syntheticornithology/audio-gan' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/syntheticornithology/audio-gan' target=\"_blank\">https://wandb.ai/syntheticornithology/audio-gan</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/syntheticornithology/audio-gan/runs/98x1il3w' target=\"_blank\">https://wandb.ai/syntheticornithology/audio-gan/runs/98x1il3w</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/syntheticornithology/audio-gan/runs/98x1il3w?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
            ],
            "text/plain": [
              "<wandb.sdk.wandb_run.Run at 0x7ffa6450fac0>"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def train_gan(audio_folder, json_folder, epochs, batch_size, learning_rate, device, save_interval, model_path):\n",
        "    # Define the MEL spectrogram transformation\n",
        "    mel_spectrogram_transform = torchaudio.transforms.MelSpectrogram(sample_rate=44100, n_mels=128, hop_length=1024, n_fft=2048)\n",
        "    mel_spectrogram_transform.n_mels = 30 # Update the number of Mel bands\n",
        "\n",
        "    dataset = AudioDataset(audio_folder, json_folder, transform=mel_spectrogram_transform)\n",
        "    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True, num_workers=2, collate_fn=collate_fn)\n",
        "\n",
        "    input_dim = 30 # Update the input dimension\n",
        "    hidden_dim = 128\n",
        "    num_layers = 1\n",
        "    audio_dim = 30  # Assuming the Mel spectrogram has 30 dimensions. Update the audio dimension\n",
        "    generator = Generator(input_dim, hidden_dim, num_layers, audio_dim).to(device)\n",
        "\n",
        "    discriminator = Discriminator(audio_dim, hidden_dim, num_layers, 1).to(device)\n",
        "\n",
        "\n",
        "    initial_generator_path = os.path.join(model_path, \"generator_initial.pth\")\n",
        "    initial_discriminator_path = os.path.join(model_path, \"discriminator_initial.pth\")\n",
        "\n",
        "    if not os.path.exists(initial_generator_path):\n",
        "        torch.save(generator.state_dict(), initial_generator_path)\n",
        "\n",
        "    if not os.path.exists(initial_discriminator_path):\n",
        "        torch.save(discriminator.state_dict(), initial_discriminator_path)\n",
        "\n",
        "    criterion = nn.BCELoss()\n",
        "    optimizer_G = optim.Adam(generator.parameters(), lr=learning_rate, betas=(0.5, 0.999))\n",
        "    optimizer_D = optim.Adam(discriminator.parameters(), lr=learning_rate, betas=(0.5, 0.999))\n",
        "\n",
        "    for epoch in range(1, epochs + 1):\n",
        "        for batch_idx, (packed_real_data, params) in enumerate(dataloader):\n",
        "            packed_real_data, params = packed_real_data.to(device), params.to(device)\n",
        "            batch_size = packed_real_data.batch_sizes[0]\n",
        "\n",
        "            # Train discriminator\n",
        "            optimizer_D.zero_grad()\n",
        "\n",
        "            noise = torch.randn(batch_size, input_dim, device=device)\n",
        "            z = torch.cat((noise.unsqueeze(1), params.unsqueeze(1)), dim=2)\n",
        "            packed_fake_data = generator(z)\n",
        "\n",
        "            real_data, _ = pad_packed_sequence(packed_real_data, batch_first=True)\n",
        "            fake_data, _ = pad_packed_sequence(packed_fake_data, batch_first=True)\n",
        "\n",
        "            real_validity = discriminator(torch.cat((real_data, params.unsqueeze(1).repeat(1, real_data.size(1), 1)), dim=2))\n",
        "\n",
        "            fake_validity = discriminator(torch.cat((fake_data.detach(), params.unsqueeze(1).repeat(1, fake_data.size(1), 1)), dim=2))\n",
        "\n",
        "            real_loss = criterion(real_validity, torch.ones(batch_size, 1, device=device))\n",
        "            fake_loss = criterion(fake_validity, torch.zeros(batch_size, 1, device=device))\n",
        "            d_loss = (real_loss + fake_loss) / 2\n",
        "\n",
        "            d_loss.backward()\n",
        "            optimizer_D.step()\n",
        "\n",
        "            # Train generator\n",
        "            optimizer_G.zero_grad()\n",
        "\n",
        "            fake_validity = discriminator(torch.cat((fake_data, params.unsqueeze(1).repeat(1, fake_data.size(1), 1)), dim=2))\n",
        "            g_loss = criterion(fake_validity, torch.ones(batch_size, 1, device=device))\n",
        "\n",
        "            g_loss.backward()\n",
        "            optimizer_G.step()\n",
        "\n",
        "            print(f\"Epoch [{epoch}/{epochs}] Batch [{batch_idx+1}/{len(dataloader)}] Loss D: {d_loss.item():.4f}, Loss G: {g_loss.item():.4f}\")\n",
        "\n",
        "        if epoch % save_interval == 0:\n",
        "            torch.save(generator.state_dict(), os.path.join(model_path, f\"generator_epoch_{epoch}.pth\"))\n",
        "            torch.save(discriminator.state_dict(), os.path.join(model_path, f\"discriminator_epoch_{epoch}.pth\"))\n",
        "\n",
        "    torch.save(generator.state_dict(), os.path.join(model_path, \"generator_final.pth\"))\n",
        "    torch.save(discriminator.state_dict(), os.path.join(model_path, \"discriminator_final.pth\"))\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "AyNFPBpgZUDo"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_audio(generator_path, params, duration, output_folder, device):\n",
        "    generator = Generator(input_dim=10 + 128 * 128, output_dim=128 * 128, hidden_size=256, num_layers=2).to(device)\n",
        "    generator.load_state_dict(torch.load(generator_path))\n",
        "    generator.eval()\n",
        "\n",
        "    params = torch.tensor(params, dtype=torch.float32).unsqueeze(0).to(device)\n",
        "    num_steps = int(duration * 44100 / 1024)\n",
        "    generated_waveforms = []\n",
        "\n",
        "    print(\"Generating audio...\")\n",
        "\n",
        "    with torch.no_grad():\n",
        "        hidden = None\n",
        "        for step in range(num_steps):\n",
        "            if hidden is None:\n",
        "                noise = torch.randn(1, 1, 128 * 128 - 10, device=device)\n",
        "            else:\n",
        "                noise = torch.randn(1, 1, 128 * 128 - 10, device=device)\n",
        "\n",
        "            z = torch.cat((noise, params.unsqueeze(1)), dim=2)\n",
        "            output, hidden = generator(z, hidden)\n",
        "            output_waveform = output.squeeze().detach().cpu()\n",
        "            generated_waveforms.append(output_waveform)\n",
        "\n",
        "            if step % (num_steps // 10) == 0:\n",
        "                print(f\"Step {step}/{num_steps}\")\n",
        "\n",
        "    print(\"Audio generation completed.\")\n",
        "\n",
        "    generated_waveform = torch.cat(generated_waveforms, dim=0)\n",
        "    generated_waveform = generated_waveform.view(1, 128, -1)\n",
        "    \n",
        "    mel_inverse = T.InverseMelScale(n_stft=1024, n_mels=128, sample_rate=44100)\n",
        "    griffin_lim = T.GriffinLim(n_fft=2048, n_iter=32)\n",
        "\n",
        "    waveform = griffin_lim(mel_inverse(generated_waveform))\n",
        "    waveform = waveform[:, :int(duration * 44100)]\n",
        "\n",
        "    timestamp = datetime.now().strftime(\"%Y-%m-%d-%H-%M-%S\")\n",
        "    output_audio_path = os.path.join(output_folder, f\"generated_audio_{timestamp}.wav\")\n",
        "    output_json_path = os.path.join(output_folder, f\"generated_audio_{timestamp}.json\")\n",
        "\n",
        "    torchaudio.save(output_audio_path, waveform, sample_rate=44100)\n",
        "\n",
        "    parameter_names = [\n",
        "        \"Latitude\",\n",
        "        \"Longitude\",\n",
        "        \"Degrees\",\n",
        "        \"Humidity\",\n",
        "        \"Wind speed\",\n",
        "        \"Wind direction\",\n",
        "        \"Pressure\",\n",
        "        \"Elevation\",\n",
        "        \"Minutes of day\",\n",
        "        \"Day of year\",\n",
        "    ]\n",
        "\n",
        "    parameter_data = {name: value for name, value in zip(parameter_names, params)}\n",
        "\n",
        "    with open(output_json_path, \"w\") as f:\n",
        "        json.dump(parameter_data, f, indent=4)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "67EZiopBZVIA"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    os.makedirs(model_path, exist_ok=True)\n",
        "\n",
        "   \n",
        "\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    train_gan(audio_folder, json_folder, epochs=100, batch_size=32, learning_rate=0.0002, device=device, save_interval=50, model_path=model_path)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "GocxAR3CeaxX",
        "outputId": "d42772ab-dd16-47d2-aaa9-08836162af69"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading 464/758: /content/drive/MyDrive/colab_storage/ronxgin_data_samples/2015-10-29-08-43-44-210_P.wav\n",
            "Loading 256/758: /content/drive/MyDrive/colab_storage/ronxgin_data_samples/2019-09-02-17-38-22-137_P.wav\n",
            "Loading 460/758: /content/drive/MyDrive/colab_storage/ronxgin_data_samples/2015-10-17-08-34-47-374_P.wav\n",
            "Loading 367/758: /content/drive/MyDrive/colab_storage/ronxgin_data_samples/2011-12-27-11-50-38-439_P.wav\n",
            "Loading 341/758: /content/drive/MyDrive/colab_storage/ronxgin_data_samples/2011-12-19-10-01-36-886_P.wav\n",
            "Loading 661/758: /content/drive/MyDrive/colab_storage/ronxgin_data_samples/2020-06-18-10-39-29-801_P.wav\n",
            "Loading 165/758: /content/drive/MyDrive/colab_storage/ronxgin_data_samples/2022-11-12-08-20-41-169_P.wav\n",
            "Loading 514/758: /content/drive/MyDrive/colab_storage/ronxgin_data_samples/2016-11-26-10-11-00-372_P.wav\n",
            "Loading 567/758: /content/drive/MyDrive/colab_storage/ronxgin_data_samples/2018-08-25-02-07-14-927_P.wav\n",
            "Loading 512/758: /content/drive/MyDrive/colab_storage/ronxgin_data_samples/2016-11-06-10-05-41-989_P.wav\n",
            "Loading 5/758: /content/drive/MyDrive/colab_storage/ronxgin_data_samples/2021-01-19-07-40-15-916_P.wav\n",
            "Loading 446/758: /content/drive/MyDrive/colab_storage/ronxgin_data_samples/2015-04-19-13-33-56-594_P.wav\n",
            "Loading 2/758: /content/drive/MyDrive/colab_storage/ronxgin_data_samples/2020-12-29-06-55-21-111_P.wav\n",
            "Loading 21/758: /content/drive/MyDrive/colab_storage/ronxgin_data_samples/2021-04-27-07-00-45-609_P.wav\n",
            "Loading 219/758: /content/drive/MyDrive/colab_storage/ronxgin_data_samples/2022-04-21-18-31-05-673_P.wav\n",
            "Loading 601/758: /content/drive/MyDrive/colab_storage/ronxgin_data_samples/2018-10-08-18-25-22-215_P.wav\n",
            "Loading 751/758: /content/drive/MyDrive/colab_storage/ronxgin_data_samples/2020-11-21-05-10-09-601_P.wav\n",
            "Loading 208/758: /content/drive/MyDrive/colab_storage/ronxgin_data_samples/2020-06-27-10-09-31-960_P.wav\n",
            "Loading 264/758: /content/drive/MyDrive/colab_storage/ronxgin_data_samples/2019-10-09-09-08-21-660_P.wav\n",
            "Loading 636/758: /content/drive/MyDrive/colab_storage/ronxgin_data_samples/2020-02-01-07-07-43-520_P.wav\n",
            "Loading 253/758: /content/drive/MyDrive/colab_storage/ronxgin_data_samples/2019-08-30-23-40-00-065_P.wav\n",
            "Loading 462/758: /content/drive/MyDrive/colab_storage/ronxgin_data_samples/2015-10-17-21-34-47-368_P.wav\n",
            "Loading 615/758: /content/drive/MyDrive/colab_storage/ronxgin_data_samples/2019-03-04-04-37-40-810_P.wav\n",
            "Loading 397/758: /content/drive/MyDrive/colab_storage/ronxgin_data_samples/2012-05-19-11-32-47-932_P.wav\n",
            "Loading 140/758: /content/drive/MyDrive/colab_storage/ronxgin_data_samples/2022-05-27-08-15-09-272_P.wav\n",
            "Loading 549/758: /content/drive/MyDrive/colab_storage/ronxgin_data_samples/2018-01-26-10-18-40-692_P.wav\n",
            "Loading 378/758: /content/drive/MyDrive/colab_storage/ronxgin_data_samples/2012-01-01-06-41-37-057_P.wav\n",
            "Loading 353/758: /content/drive/MyDrive/colab_storage/ronxgin_data_samples/2011-12-22-17-34-37-718_P.wav\n",
            "Loading 50/758: /content/drive/MyDrive/colab_storage/ronxgin_data_samples/2021-08-28-08-03-10-832_P.wav\n",
            "Loading 239/758: /content/drive/MyDrive/colab_storage/ronxgin_data_samples/2022-11-24-09-42-44-703_P.wav\n",
            "Loading 65/758: /content/drive/MyDrive/colab_storage/ronxgin_data_samples/2021-10-02-08-11-21-674_P.wav\n",
            "Loading 218/758: /content/drive/MyDrive/colab_storage/ronxgin_data_samples/2018-11-17-07-09-23-104_P.wav\n",
            "Loading 203/758: /content/drive/MyDrive/colab_storage/ronxgin_data_samples/2016-09-04-14-05-54-596_P.wav\n",
            "Loading 695/758: /content/drive/MyDrive/colab_storage/ronxgin_data_samples/2020-07-29-09-39-39-748_P.wav\n",
            "Loading 473/758: /content/drive/MyDrive/colab_storage/ronxgin_data_samples/2016-01-06-19-05-28-678_P.wav\n",
            "Loading 616/758: /content/drive/MyDrive/colab_storage/ronxgin_data_samples/2019-03-04-01-07-40-762_P.wav\n",
            "Loading 89/758: /content/drive/MyDrive/colab_storage/ronxgin_data_samples/2021-10-30-08-02-32-338_P.wav\n",
            "Loading 58/758: /content/drive/MyDrive/colab_storage/ronxgin_data_samples/2021-09-19-09-11-15-709_P.wav\n",
            "Loading 508/758: /content/drive/MyDrive/colab_storage/ronxgin_data_samples/2016-10-24-17-05-40-124_P.wav\n",
            "Loading 515/758: /content/drive/MyDrive/colab_storage/ronxgin_data_samples/2016-12-04-12-05-45-116_P.wav\n",
            "Loading 373/758: /content/drive/MyDrive/colab_storage/ronxgin_data_samples/2011-12-28-10-15-37-018_P.wav\n",
            "Loading 62/758: /content/drive/MyDrive/colab_storage/ronxgin_data_samples/2021-10-02-04-11-29-103_P.wav\n",
            "Loading 330/758: /content/drive/MyDrive/colab_storage/ronxgin_data_samples/2010-10-06-09-40-34-309_P.wav\n",
            "Loading 375/758: /content/drive/MyDrive/colab_storage/ronxgin_data_samples/2011-12-30-13-49-37-721_P.wav\n",
            "Loading 75/758: /content/drive/MyDrive/colab_storage/ronxgin_data_samples/2021-10-06-14-11-29-349_P.wav\n",
            "Loading 25/758: /content/drive/MyDrive/colab_storage/ronxgin_data_samples/2021-05-03-07-06-44-954_P.wav\n",
            "Loading 589/758: /content/drive/MyDrive/colab_storage/ronxgin_data_samples/2018-09-04-05-07-19-607_P.wav\n",
            "Loading 167/758: /content/drive/MyDrive/colab_storage/ronxgin_data_samples/2022-12-13-06-42-51-892_P.wav\n",
            "Loading 370/758: /content/drive/MyDrive/colab_storage/ronxgin_data_samples/2011-12-28-07-34-38-391_P.wav\n",
            "Loading 42/758: /content/drive/MyDrive/colab_storage/ronxgin_data_samples/2021-06-28-08-02-03-357_P.wav\n",
            "Loading 245/758: /content/drive/MyDrive/colab_storage/ronxgin_data_samples/2022-05-02-06-23-15-191_P.wav\n",
            "Loading 287/758: /content/drive/MyDrive/colab_storage/ronxgin_data_samples/2019-12-14-05-27-37-603_P.wav\n",
            "Loading 493/758: /content/drive/MyDrive/colab_storage/ronxgin_data_samples/2016-06-07-04-35-24-198_P.wav\n",
            "Loading 716/758: /content/drive/MyDrive/colab_storage/ronxgin_data_samples/2020-08-31-05-11-10-640_P.wav\n",
            "Loading 606/758: /content/drive/MyDrive/colab_storage/ronxgin_data_samples/2018-11-30-15-07-43-945_P.wav\n",
            "Loading 189/758: /content/drive/MyDrive/colab_storage/ronxgin_data_samples/2012-12-20-06-38-41-522_P.wav\n",
            "Loading 172/758: /content/drive/MyDrive/colab_storage/ronxgin_data_samples/2022-12-17-08-42-52-333_P.wav\n",
            "Loading 37/758: /content/drive/MyDrive/colab_storage/ronxgin_data_samples/2021-06-23-08-40-58-582_P.wav\n",
            "Loading 390/758: /content/drive/MyDrive/colab_storage/ronxgin_data_samples/2012-01-06-18-26-38-488_P.wav\n",
            "Loading 455/758: /content/drive/MyDrive/colab_storage/ronxgin_data_samples/2015-10-14-07-34-46-726_P.wav\n",
            "Loading 144/758: /content/drive/MyDrive/colab_storage/ronxgin_data_samples/2022-08-04-11-12-27-415_P.wav\n",
            "Loading 655/758: /content/drive/MyDrive/colab_storage/ronxgin_data_samples/2020-06-07-08-16-28-583_P.wav\n",
            "Loading 23/758: /content/drive/MyDrive/colab_storage/ronxgin_data_samples/2021-05-01-08-27-44-207_P.wav\n",
            "Loading 578/758: /content/drive/MyDrive/colab_storage/ronxgin_data_samples/2018-08-29-06-07-16-585_P.wav\n",
            "Loading 591/758: /content/drive/MyDrive/colab_storage/ronxgin_data_samples/2018-09-04-07-37-19-609_P.wav\n",
            "Loading 360/758: /content/drive/MyDrive/colab_storage/ronxgin_data_samples/2011-12-25-07-15-38-195_P.wav\n",
            "Loading 174/758: /content/drive/MyDrive/colab_storage/ronxgin_data_samples/2023-01-08-07-36-55-399_P.wav\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-77-c3bae440ed7a>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cuda\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"cpu\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mtrain_gan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maudio_folder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjson_folder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.0002\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_interval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-76-a17eee5fbc46>\u001b[0m in \u001b[0;36mtrain_gan\u001b[0;34m(audio_folder, json_folder, epochs, batch_size, learning_rate, device, save_interval, model_path)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mpacked_real_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m             \u001b[0mpacked_real_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpacked_real_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m             \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpacked_real_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_sizes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    626\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    627\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 628\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    629\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    630\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1331\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1332\u001b[0m                 \u001b[0;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_task_info\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1333\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1334\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1335\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_try_put_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_process_data\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m   1357\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_put_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1358\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mExceptionWrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1359\u001b[0;31m             \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1360\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1361\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/_utils.py\u001b[0m in \u001b[0;36mreraise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    541\u001b[0m             \u001b[0;31m# instantiate since we don't know how to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    542\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 543\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mexception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    544\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    545\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: Caught IndexError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/usr/local/lib/python3.9/dist-packages/torch/utils/data/_utils/worker.py\", line 302, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"/usr/local/lib/python3.9/dist-packages/torch/utils/data/_utils/fetch.py\", line 61, in fetch\n    return self.collate_fn(data)\n  File \"<ipython-input-74-af1c1f6979dc>\", line 52, in collate_fn\n    padded_batch = [(\n  File \"<ipython-input-74-af1c1f6979dc>\", line 55, in <listcomp>\n    item[2]  # Parameters\nIndexError: tuple index out of range\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Example file generation\n",
        "if __name__ == \"__main__\":\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "  \n",
        "    generator_path = os.path.join(model_path, \"generator_final.pth\")\n",
        "    params = [-24.8874 ,150.9657 , 23.16 , 73 , 4.78 , 8 , 1015 , 506 , 546 , 110]  # Replace with actual parameters\n",
        "    duration = 5.0  # In seconds\n",
        "\n",
        "    generate_audio(generator_path, params, duration, output_path, device)"
      ],
      "metadata": {
        "id": "67CicNbGZfdh"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}